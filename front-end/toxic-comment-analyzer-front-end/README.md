# Toxic Comment Analyzer

Toxic Comment Analyzer is a tool developed to assist in identifying and analyzing potentially harmful online speech, particularly in the form of toxic comments. Powered by an Artificial Intelligence model, this application uses a Logistic Regression model that has been trained on a public comments dataset to classify a comment based on its toxicity level and other harmful attributes such as insults, obscenity, identity hate, threats, etc.

# Working Demo
https://alhanielbaya.github.io/toxic-comment-analyzer